{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63505c8-05b1-4842-ba12-76d23727c395",
   "metadata": {},
   "source": [
    "# Predicting Playing Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8c0eaa-3be4-4a20-af91-e6283157c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import PIL\n",
    "import PIL.Image \n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb45fe1-057f-4560-a947-b3d91060b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_dir = 'D:\\card_data\\cv_num_cards_deck\\images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2cfa84-7c5d-4060-9afe-bbfe8305e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beada7ae-300c-4059-91da-3fb6771ba819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3811 files belonging to 3 classes.\n",
      "Using 3049 files for training.\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    local_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width), # specified the resizing \n",
    "    batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300e83c9-b44a-4188-b90d-4ffe66d17c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3811 files belonging to 3 classes.\n",
      "Using 762 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Create the validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    local_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07bb1b28-fd64-4a3c-aa05-7dad9ca6d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-13', '14-39', '40-52']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3eed15f-8aab-49fd-8344-a1005c33bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first 9 images from the dataset\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791356ca-87e3-41c9-a7a5-92d5529676fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# image preprocessing \n",
    "normalization_layer = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "augmented_ds = train_ds.map(lambda x, y: (data_augmentation(normalization_layer(x)), y))\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71be929-01af-49cd-9327-67465ce8821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need comments\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f83f61-3f5c-4145-a5df-90f2a644dca3",
   "metadata": {},
   "source": [
    "# Training our own Neural Network \n",
    "We're first going to try training our own convolutional neural network using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c11902-4310-452f-9ba7-54fc9afa0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "model = tf.keras.Sequential([ # rescaling layer \n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'), # relu activation function\n",
    "  tf.keras.layers.MaxPooling2D(), # maxpooling layer \n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'), # convolution layer  \n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ffecc0-0260-4975-aa9a-dfc370a0d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3fc457c-7009-40f3-bf48-35e69654c029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "96/96 [==============================] - 10s 66ms/step - loss: 3.2060 - accuracy: 0.7514 - val_loss: 436.1129 - val_accuracy: 0.5840\n",
      "Epoch 2/4\n",
      "96/96 [==============================] - 6s 56ms/step - loss: 0.0706 - accuracy: 0.9846 - val_loss: 601.9551 - val_accuracy: 0.4961\n",
      "Epoch 3/4\n",
      "96/96 [==============================] - 6s 55ms/step - loss: 0.0163 - accuracy: 0.9993 - val_loss: 623.3667 - val_accuracy: 0.4475\n",
      "Epoch 4/4\n",
      "96/96 [==============================] - 6s 55ms/step - loss: 0.0080 - accuracy: 0.9997 - val_loss: 657.7772 - val_accuracy: 0.4436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273f308abe0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  normalized_ds, # augmented_ds\n",
    "  validation_data=val_ds,\n",
    "  epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb45bd-f0b6-49b2-9e88-cfb4e7eaef2b",
   "metadata": {},
   "source": [
    "## Assessing predictions from our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98bc223e-9770-4560-b2e1-e2344cee37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prediction(image_path):\n",
    "    image = PIL.Image.open(image_path).resize((img_width, img_height))\n",
    "    image_array = np.array(image) / 255.0  # Scale pixel values to 0-1\n",
    "    image_array = np.expand_dims(image_array, axis=0)  # Add a batch dimension\n",
    "    predictions = model.predict(image_array)\n",
    "    probabilities = tf.nn.softmax(predictions[0])  # Apply softmax to convert logits to probabilities\n",
    "    predicted_class = np.argmax(probabilities)  # Get the index of the highest probability\n",
    "    print(f\"Predicted class: {predicted_class}, Probability: {probabilities[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b6b1e22-c4f4-4548-b748-197e466be863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "Predicted class: 1, Probability: 0.5722769498825073\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted class: 1, Probability: 0.9562381505966187\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted class: 1, Probability: 0.5717422366142273\n"
     ]
    }
   ],
   "source": [
    "image_prediction('test_images/A.JPG')\n",
    "image_prediction('test_images/52b.JPG')\n",
    "image_prediction('test_images/39.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c32d3-e791-4360-86fb-7f645f1c33b4",
   "metadata": {},
   "source": [
    "Our model is assessing all three classes as the same class with very similar probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c830c0-ff06-4cda-8ad2-96f945830287",
   "metadata": {},
   "source": [
    "# Transfer Learning with ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a152a2d-be85-4b58-a72f-afe0addd72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = img_size + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2737c7e2-6c95-413a-823c-50aacf29d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2957b8cc-af34-419d-b7c1-5d36fb75d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7, 7, 1280)\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(augmented_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9defacf-7d46-44d5-aac5-ee62ab6926cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1280)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4132d18c-5ed1-4a18-a217-e63866591423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ba802bc-9628-4676-87f8-97c1355945e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "# x = preprocess_input(x) # inputs are already preprocessed\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f394093-8caf-483c-9912-e7d849b0b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "164a85eb-4c7d-4f55-ab1b-4db8b02715ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 35ms/step - loss: 0.2947 - accuracy: 0.3268\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db04cd-b791-472e-833e-bea1e710757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      " 3/96 [..............................] - ETA: 21s - loss: 1.0434 - accuracy: 0.3438"
     ]
    }
   ],
   "source": [
    "history = model.fit(augmented_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0e108-50cb-441a-ab50-368233a00c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = val_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2bac6-1194-4ec7-ac37-0818bfaf4fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
